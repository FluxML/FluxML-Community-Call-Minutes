# Notes on 16 Aug. 2022

## Agenda

- Discuss [tagged functors issue](https://github.com/FluxML/Functors.jl/issues/41)

## Minutes

Kyle gave an overview of Functors.jl and the issue:
- Flux does not use super types or interfaces by design (to reduce boilerplate)
- Functors.jl allows us to manipulate layers by walking deeply nested structures
- A _functor_ (defined by calling `@functor MyType`) has a subset of its fields that are considered _children_
- Functors.jl let's us define the children of a type and manipulate types by recursively walking the children
- Some children are special (i.e. trainable parameters), so Flux has `trainable(...)` as an interface that can be overloaded to separate the trainable fields from the rest of the children
- There are many properties beyond being trainable that we want a field to have...this motivates the issue
- Taggable functors would let us associate many "tags" with each field (i.e. `:trainable` is a tag)

We had some discussion on whether lenses (in particular Accessors.jl) will be a better solution here. StructWalk.jl was also suggested as a more comprehensive package for walking structures that allows parameterizing the walk better than Functors.jl. Are we hitting the limitations of Functors.jl?

Some community members asked clarifying questions about how this system would work with pruning. This got at a fundamental difference between Flux and other frameworks. For example, other frameworks might have a "pruneable conv" that is a convolution with the forward pass overridden, etc. In Flux, we prefer to wrap the parameter arrays themselves instead of the layers. This allows us to build mechanisms what will work just as well for custom layers as the built in ones. And no need to define a separate "pruneable" layer for every type.

Final decision was to let Kyle submit a PR on the taggable functors concept with some usage examples. Others might submit PRs on how the same functionality would look with StructWalk.jl etc. This can serve as a comparison point for if we transition away from Functors.jl.

### Chat transcript

```
11:17:27 From Dhairya Gandhi to Everyone:
	im in a noisy place, so I can't speak nuch
11:17:39 From Kyle Daruwalla to Everyone:
	No problem!
11:20:11 From Kyle Daruwalla to Everyone:
	https://github.com/FluxML/Functors.jl/issues/41
11:27:06 From Dhairya Gandhi to Everyone:
	what should the tag be used for?
11:27:57 From Dhairya Gandhi to Everyone:
	it seems like we need a lens. a tag might be restrictive. the walk can effectively be the lens
11:29:21 From Brian Chen to Everyone:
	https://github.com/chengchingwen/StructWalk.jl
11:29:50 From Dhairya Gandhi to Everyone:
	accessors.jl doesn't last i checked. but a consistent method would be best.
11:31:17 From Ari to Everyone:
	https://www.tensorflow.org/probability/oryx/notebooks/a_tour_of_oryx
11:31:53 From Ari to Everyone:
	grist for the design discussion mill
11:32:40 From Dhairya Gandhi to Everyone:
	exactly - a tag would need to be dynamic. so it's not extendable in quite the same way a lens is. we already have a way to mark fields that walks are allowed over or not
11:33:47 From Dhairya Gandhi to Everyone:
	also, ForwardDiff tried the tag approach and that runs into corner cases in my experience.
11:34:10 From Kyle Daruwalla to Everyone:
	Can everyone hear me?
11:54:59 From Harish to Everyone:
	I gtg, thanks everyone!
```
