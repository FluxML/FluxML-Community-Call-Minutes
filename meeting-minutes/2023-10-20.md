# Notes on 20 Oct. 2023

## Agenda

- Tracker.jl + ChainRules integration challenges (@MariusDrulea)
- Attention layers and models in Metalhead (@theabhirath)
- Feedback on proposed structure for FluxMLDocs (@theabhirath)

## Minutes

**Video link:** https://youtu.be/ZcctnWm2P_8

Tracker.jl + ChainRules:
- Second-order rules had errors due to how Tracker.jl custom rules were written
- Marius and Jonas have been porting Tracker.jl to use ChainRules
- Initial port is complete
- Issues with second order rules still:
    - Suppose we have a custom rule for a function `f(x)`
    - The first order primal is `x -> f(x)`
    - After calling `back!(f(x))`, the graph grows another branch from `x`: `x -> pb(delta, x)`
    - The result of `pb` is not a tracked number since the current implementation discards tracking info before calling ChainRules
    - Can't trivially run the `rrule` on tracked data, since this will result in stack overflow from the `rrule` getting called on every primal evaluation inside `rrule`
    - Quick fix is to add `@thunk` in the custom `rrule` primal evaluation
    - Alternative: never call `data` and define an `rrule` for `track` itself

FluxML docs updates:
- Abhirath has initial multidoc prototype
- Feedback on top bar header:
    - Follow SciML's lead: https://docs.sciml.ai/Overview/stable/
    - Headers for "Data processing", "Training", "Models"
    - NNlib API on sidebar are redundant now

Metalhead updates:
- Abhirath wants to add example attention mechanisms for vision transformers
    - Using TensorCast or Tullio to reshape before NNlib attention call
    - Most frameworks rewrite attention from scratch per model to accommodate variety of attention layers
    - Abhirath will explore performance of `einops`-like libraries in Julia
